{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: AutoEncoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task :\n",
    "\n",
    "<ul>\n",
    "<li>DAC: Deep Autoencoder-based Clustering.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Model\n",
    "\n",
    "Figure 1 shows an overview of our deep autoencoder-based clustering framework. There\n",
    "are two main steps: training and clustering testing. In the training step, a deep autoencoder with an encoder and a decoder is trained using the training set. Here a flattened\n",
    "input vector is fed into the multilayer deep encoder which has a low dimensional learned\n",
    "representation. This learned representation is further fed into a decoder that tries to recover an output of the same size as the input. The training process of this autoencoder\n",
    "tries to reconstruct the input as much as possible. In the following clustering step, we\n",
    "apply the autoencoder to the testing set. The output of the encoder (learned representations) is then fed to a classic K-Means algorithm to do clustering. The learned low\n",
    "dimensional representation vector contains key information of the given input, and thus\n",
    "yield better clustering results.\n",
    "\n",
    "- Source-paper: DAC: Deep Autoencoder-based Clustering, a General Deep Learning Framework of Representation Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Q3-model.png\" width = 500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch for Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# TensorFlow and Keras for Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# scikit-learn for clustering\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Designing Deep Auto Encoder Cluster Model ( based on given figure )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, encoded_dim=10):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, encoded_dim)  # Latent space representation\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoded_dim, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid()  # Sigmoid activation for final output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_dim = 784  # MNIST images are 28x28 pixels\n",
    "encoded_dim = 10\n",
    "\n",
    "autoencoder = Autoencoder(input_dim, encoded_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import, Normalize, and Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data to the range [0, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
    "\n",
    "# Download and load the training dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.07313347607851028\n",
      "Epoch [2/20], Loss: 0.06859830766916275\n",
      "Epoch [3/20], Loss: 0.07338949292898178\n",
      "Epoch [4/20], Loss: 0.062432266771793365\n",
      "Epoch [5/20], Loss: 0.07072839885950089\n",
      "Epoch [6/20], Loss: 0.10643003135919571\n",
      "Epoch [7/20], Loss: 0.10137803107500076\n",
      "Epoch [8/20], Loss: 0.11038287729024887\n",
      "Epoch [9/20], Loss: 0.11204873025417328\n",
      "Epoch [10/20], Loss: 0.10847843438386917\n",
      "Epoch [11/20], Loss: 0.11162326484918594\n",
      "Epoch [12/20], Loss: 0.11785528808832169\n",
      "Epoch [13/20], Loss: 0.11236056685447693\n",
      "Epoch [14/20], Loss: 0.11572087556123734\n",
      "Epoch [15/20], Loss: 0.11039432138204575\n",
      "Epoch [16/20], Loss: 0.11167068779468536\n",
      "Epoch [17/20], Loss: 0.11208735406398773\n",
      "Epoch [18/20], Loss: 0.10728941857814789\n",
      "Epoch [19/20], Loss: 0.10215115547180176\n",
      "Epoch [20/20], Loss: 0.11073541641235352\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.003)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "sample_size = 1000  # Number of samples to use for training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        inputs, _ = batch\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "\n",
    "        # Limit the number of samples for training\n",
    "        if sample_size is not None and len(inputs) > sample_size:\n",
    "            inputs = inputs[:sample_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        encoded, decoded = autoencoder(inputs)\n",
    "\n",
    "        # Compute the MSE loss by comparing the decoded output with the input\n",
    "        loss = criterion(decoded, inputs)\n",
    "\n",
    "        # Add the regularization term\n",
    "        loss += 0.000001 * (decoded ** 2).sum()\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
