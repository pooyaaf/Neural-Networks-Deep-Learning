{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Control VAE\n",
        "\n",
        "* Dataset -  dSprites (2D shape)\n",
        "* Models: VAE | Control VAE"
      ],
      "metadata": {
        "id": "jqiZg217Ne5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "P0eFmol8NZca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Lambda, Reshape, Flatten, LeakyReLU, Softmax\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import click"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-1. Intro - load data"
      ],
      "metadata": {
        "id": "r4nJvwzuOV_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNYYR0r4OXdR",
        "outputId": "7170ad24-e3fe-48e2-b99c-d5b2fddeb191"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"sh3_sc6_y32_x32_imgs.npz\"\n",
        "path_file = \"/content/drive/MyDrive/Dataset/sh3_sc6_y32_x32_imgs.npz\"\n",
        "imgs = np.load(path_file, allow_pickle=True, encoding='latin1')\n",
        "imgs = imgs['imgs']"
      ],
      "metadata": {
        "id": "t5bOf1tbOjjt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(f\"Image {i + 1} size: {imgs[i].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC9fFszqPZcN",
        "outputId": "218db033-07cc-4485-df0d-873774d13e3a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 1 size: (64, 64)\n",
            "Image 2 size: (64, 64)\n",
            "Image 3 size: (64, 64)\n",
            "Image 4 size: (64, 64)\n",
            "Image 5 size: (64, 64)\n",
            "Image 6 size: (64, 64)\n",
            "Image 7 size: (64, 64)\n",
            "Image 8 size: (64, 64)\n",
            "Image 9 size: (64, 64)\n",
            "Image 10 size: (64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "num_samples_to_display = 10\n",
        "\n",
        "for i in range(num_samples_to_display):\n",
        "    plt.subplot(1, num_samples_to_display, i + 1)\n",
        "    plt.imshow(imgs[i+1000])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "T4AsUAj6Ougt",
        "outputId": "a880a0c4-0150-4835-def8-6528b058b0b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAA+CAYAAAC2oBgNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAERklEQVR4nO3d32vVdRjA8eecs+E0zNyOKYXZbKcf6h8Q3UQXgVQgZFESNOkuLbqIiC4qCrrtNn9gCEVEBUFUF2pBFKSkZSFmNaxEMLfljxbk3M6+XdRFcL6CbfN8z/d8Xq/LPWM8H9jFm2dsq2RZlgUAkKxq0QsAAMUSAwCQODEAAIkTAwCQODEAAIkTAwCQODEAAIkTAwCQODEAAInrudxPvLv64JXcY17tnXn3krNueUdE97ylW94R0T1v6ZZ3RHTPW7rlHRHd85ZueUeEywAAJE8MAEDixAAAJE4MAEDixAAAJE4MAEDixAAAJE4MAEDixAAAJE4MAEDiLvvPEbdbddGi+OuutZFVKi2zRSf/jJnDRwvYCgC6T8fGQGXV9fHJju1Rq7QeL27+bDgGNxWw1Cz0rFgeR19ZGdHaNNF/oDfq279s/1IA8B8dGwPdIlt6dYys35EfNQuHo769gKVmqdrXFxfuXBeRc63pOzkRM0eOFbAVAHMlBrhslcGVse/1S4RNia41teXXxvcvr8q91gx81RMDO11rgLSIAdLTvyRG7rvEj6AWD8fAzgJ2mqXa0GBs/vjTqEXWMntm76ZobD1QwFb/X7WvLy7esTY30Bacmojm0R/bvxQkRAxAmfX2xMarzuaGzXP9FwpYaHYqgytjzxs7S391ivj38vTijfmXp4O1GNjl8kTnEQMA86l/SYxs2JYfNtcMx8CuAnaahdrQYDz84edRq7RenZ7f80A0nizH1SkiorJgQTRvX5M76/1tIpo/jLR5o87TuTEwdiZufXNrfl1/2/rNCcA86u2JRxaP5kbNS/XyXJ0iIqqrb4iP3tpV+stTbdmyOPbC6txZ/VA1lu6e/dWpY2OgOf57rH62/Oe0mZFf494Nj+bOGuNnY7rN+8xFZXIqXj3byP35dPPUwgI2AkhI/Zr46f7X8qOmPhxLd8/+S3dsDHSLbOpixMEjubMyhUBExPTxX2LfusW5s6HY3+Zt5mD8XNzy9pbIcq5O9W9yPgjQ5cQAyWmOjcVNT48Vvca8mDl+Iu7ZuDl31hg9X5rgrExOxbbzq6IWMy2z5mlXJ7jSxACUWDY5GbH/u9xZWUIg4p+r0wdrBnJnpbo6RUSMn4vGe1tyR/WvXZ7oTGIAYB41x8ai8VT5L08zx0/E+ocey50NjU5Es837zMnUdOz+47qoVVovT9NjfQUs1HnEAAAtssnJqH5xOHdWqhCIiObIz/HObStyZ40oz69Ixpnz0Xj/8fzfsjs0t39CLAYAoASap0ej8cToFfnac0sJAKD0xAAAJE4MAEDixAAAJE4MAEDixAAAJE4MAEDixAAAJE4MAEDixAAAJE4MAEDixAAAJE4MAEDixAAAJE4MAEDixAAAJK6SZVlW9BIAQHFcBgAgcWIAABInBgAgcWIAABInBgAgcWIAABInBgAgcWIAABInBgAgcX8D6+boJvyRVrUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "N6RiNZ2xTx-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "\n",
        "class DspritesDataset(Dataset):\n",
        "    def __init__(self, imgs):\n",
        "        self.data = imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = torch.from_numpy(self.data[idx]).float()\n",
        "        sample = sample.unsqueeze(0)\n",
        "        return sample\n",
        "\n",
        "def load_dsprites(file_name, path_file, batch_size=64, validation_split=0.2, shuffle_dataset=True, random_seed=42):\n",
        "    # Load the dataset\n",
        "    imgs = np.load(path_file, allow_pickle=True, encoding='latin1')['imgs']\n",
        "\n",
        "    # Define the transformations\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    # Create the dataset\n",
        "    dataset = DspritesDataset(imgs)\n",
        "\n",
        "    # Split the dataset into training and validation sets\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "    if shuffle_dataset:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Example usage\n",
        "file_name = \"sh3_sc6_y32_x32_imgs.npz\"\n",
        "path_file = \"/content/drive/MyDrive/Dataset/sh3_sc6_y32_x32_imgs.npz\"\n",
        "train_loader, val_loader = load_dsprites(file_name, path_file, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "SIkOn3ZLTzk6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSraIh9wZZi1",
        "outputId": "9dad1bf2-831f-4de7-b221-dd38c0fcd064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x77fffa864b20>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Image shape:\", imgs[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFH3ch0ifZFx",
        "outputId": "8a551642-09be-4a44-95b5-f922e3dc0b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE For Test"
      ],
      "metadata": {
        "id": "5DE-maq1PqlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "class VAE_Simple(nn.Module):\n",
        "    def __init__(self, input_size=64*64, hidden_size=256, latent_size=10):\n",
        "        super(VAE_Simple, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc21 = nn.Linear(hidden_size, latent_size)\n",
        "        self.fc22 = nn.Linear(hidden_size, latent_size)\n",
        "        self.fc3 = nn.Linear(latent_size, hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        return self.fc21(h), self.fc22(h)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 64*64))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 64*64), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD\n",
        "\n",
        "model = VAE_Simple()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "def accuracy(recon_x, x):\n",
        "    # Use a threshold to determine predicted class\n",
        "    predicted = recon_x.view(-1) > 0.5\n",
        "    correct = (predicted == x.view(-1).byte()).float()\n",
        "    acc = correct.sum() / x.numel()\n",
        "    return acc.item()\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "\n",
        "    for data in train_loader:\n",
        "        inputs = data.float()\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(inputs)\n",
        "        loss = loss_function(recon_batch, inputs, mu, logvar)\n",
        "        acc = accuracy(recon_batch, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += acc\n",
        "\n",
        "    average_loss = total_loss / len(train_loader.dataset)\n",
        "    average_acc = total_acc / len(train_loader.dataset)\n",
        "\n",
        "    print(f'Train Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}, Acc: {average_acc:.4f}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            inputs = data.float()\n",
        "            recon_batch, mu, logvar = model(inputs)\n",
        "            loss = loss_function(recon_batch, inputs, mu, logvar)\n",
        "            acc = accuracy(recon_batch, inputs)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += acc\n",
        "\n",
        "    average_val_loss = val_loss / len(val_loader.dataset)\n",
        "    average_val_acc = val_acc / len(val_loader.dataset)\n",
        "\n",
        "    print(f'Validation Epoch {epoch + 1}/{num_epochs}, Loss: {average_val_loss:.4f}, Acc: {average_val_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgCSNK3lS5eq",
        "outputId": "63e01ffa-f25a-418e-f306-61b0b3a41224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch 1/2, Loss: 1053.4529, Acc: 0.0113\n",
            "Validation Epoch 1/2, Loss: 157.5542, Acc: 0.0030\n",
            "Train Epoch 2/2, Loss: 497.7572, Acc: 0.0120\n",
            "Validation Epoch 2/2, Loss: 93.8927, Acc: 0.0030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        self.fc_mu = nn.Linear(128*8*8, 64)\n",
        "        self.fc_logvar = nn.Linear(128*8*8, 64)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 128*8*8),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 8, 8)),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decoder(z)\n",
        "        return x_recon, mu, logvar\n",
        "\n",
        "# Instantiate the model and set up the optimizer\n",
        "vae = VAE()\n",
        "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(2):  # Change the number of epochs as needed\n",
        "    vae.train()\n",
        "    for data in train_loader:\n",
        "        inputs = data.float()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        recon_batch, mu, logvar = vae(inputs)\n",
        "\n",
        "        # Compute the reconstruction loss and the KL divergence\n",
        "        reconstruction_loss = F.binary_cross_entropy(recon_batch, inputs, reduction='sum')\n",
        "        kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        # Total loss\n",
        "        loss = reconstruction_loss + kl_divergence\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"Epoch {}, Loss: {:.4f}\".format(epoch + 1, loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBqSQveglAmN",
        "outputId": "216df231-ac8a-45ac-aacb-3cfc24c3caca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 200343.4844\n",
            "Epoch 1, Loss: 187094.2344\n",
            "Epoch 1, Loss: 161637.2344\n",
            "Epoch 1, Loss: 111929.9141\n",
            "Epoch 1, Loss: 248640.4375\n",
            "Epoch 1, Loss: 86558.6094\n",
            "Epoch 1, Loss: 74277.8281\n",
            "Epoch 1, Loss: 77315.6328\n",
            "Epoch 1, Loss: 75913.8672\n",
            "Epoch 1, Loss: 72406.0391\n",
            "Epoch 1, Loss: 65561.2969\n",
            "Epoch 1, Loss: 59326.8242\n",
            "Epoch 1, Loss: 58188.1836\n",
            "Epoch 1, Loss: 50564.7227\n",
            "Epoch 1, Loss: 57239.1797\n",
            "Epoch 1, Loss: 58016.9258\n",
            "Epoch 1, Loss: 59292.4570\n",
            "Epoch 1, Loss: 55560.2305\n",
            "Epoch 1, Loss: 52384.4922\n",
            "Epoch 1, Loss: 51773.2383\n",
            "Epoch 1, Loss: 49927.4961\n",
            "Epoch 1, Loss: 47015.9727\n",
            "Epoch 1, Loss: 52367.4609\n",
            "Epoch 1, Loss: 46226.6172\n",
            "Epoch 1, Loss: 47960.8438\n",
            "Epoch 1, Loss: 45853.7656\n",
            "Epoch 1, Loss: 40178.5938\n",
            "Epoch 1, Loss: 38617.7422\n",
            "Epoch 1, Loss: 40911.1875\n",
            "Epoch 1, Loss: 38808.9922\n",
            "Epoch 1, Loss: 42135.5156\n",
            "Epoch 1, Loss: 43340.3281\n",
            "Epoch 1, Loss: 38395.1719\n",
            "Epoch 1, Loss: 40507.4883\n",
            "Epoch 1, Loss: 40143.1719\n",
            "Epoch 1, Loss: 42428.0625\n",
            "Epoch 1, Loss: 45997.1875\n",
            "Epoch 1, Loss: 41528.4766\n",
            "Epoch 1, Loss: 39782.7266\n",
            "Epoch 1, Loss: 42134.8164\n",
            "Epoch 1, Loss: 40686.1016\n",
            "Epoch 1, Loss: 39087.1523\n",
            "Epoch 1, Loss: 38117.3984\n",
            "Epoch 1, Loss: 40367.9141\n",
            "Epoch 1, Loss: 37131.7070\n",
            "Epoch 1, Loss: 40418.9062\n",
            "Epoch 1, Loss: 39860.3125\n",
            "Epoch 1, Loss: 38284.2305\n",
            "Epoch 1, Loss: 36806.1914\n",
            "Epoch 1, Loss: 38864.7266\n",
            "Epoch 1, Loss: 37286.2266\n",
            "Epoch 1, Loss: 37710.9023\n",
            "Epoch 1, Loss: 39490.8438\n",
            "Epoch 1, Loss: 40902.9141\n",
            "Epoch 1, Loss: 37823.9570\n",
            "Epoch 1, Loss: 38150.2852\n",
            "Epoch 1, Loss: 38402.1445\n",
            "Epoch 1, Loss: 38774.0703\n",
            "Epoch 1, Loss: 39559.8516\n",
            "Epoch 1, Loss: 37976.0312\n",
            "Epoch 1, Loss: 35598.5273\n",
            "Epoch 1, Loss: 36423.5234\n",
            "Epoch 1, Loss: 37769.1719\n",
            "Epoch 1, Loss: 39273.8242\n",
            "Epoch 1, Loss: 33926.8828\n",
            "Epoch 1, Loss: 43075.5234\n",
            "Epoch 1, Loss: 35410.2344\n",
            "Epoch 1, Loss: 36114.7500\n",
            "Epoch 1, Loss: 36671.1328\n",
            "Epoch 1, Loss: 37221.7852\n",
            "Epoch 1, Loss: 35196.8516\n",
            "Epoch 1, Loss: 32473.7910\n",
            "Epoch 1, Loss: 38158.0664\n",
            "Epoch 1, Loss: 42196.2148\n",
            "Epoch 1, Loss: 34496.8086\n",
            "Epoch 1, Loss: 37115.0352\n",
            "Epoch 1, Loss: 36055.0078\n",
            "Epoch 1, Loss: 38115.3047\n",
            "Epoch 1, Loss: 35787.3984\n",
            "Epoch 1, Loss: 35248.0586\n",
            "Epoch 1, Loss: 38206.4102\n",
            "Epoch 1, Loss: 39487.5000\n",
            "Epoch 1, Loss: 38560.6875\n",
            "Epoch 1, Loss: 36766.9883\n",
            "Epoch 1, Loss: 36522.1094\n",
            "Epoch 1, Loss: 38325.1797\n",
            "Epoch 1, Loss: 35213.4336\n",
            "Epoch 1, Loss: 37701.5156\n",
            "Epoch 1, Loss: 36367.7422\n",
            "Epoch 1, Loss: 39167.0859\n",
            "Epoch 1, Loss: 36914.7383\n",
            "Epoch 1, Loss: 38689.8516\n",
            "Epoch 1, Loss: 38016.9453\n",
            "Epoch 1, Loss: 38406.4688\n",
            "Epoch 1, Loss: 35073.4688\n",
            "Epoch 1, Loss: 37919.9766\n",
            "Epoch 1, Loss: 37995.1328\n",
            "Epoch 1, Loss: 35182.8984\n",
            "Epoch 1, Loss: 35825.2539\n",
            "Epoch 1, Loss: 37019.9180\n",
            "Epoch 1, Loss: 35274.2969\n",
            "Epoch 1, Loss: 36185.3086\n",
            "Epoch 1, Loss: 34399.9141\n",
            "Epoch 1, Loss: 38279.3086\n",
            "Epoch 1, Loss: 34307.5859\n",
            "Epoch 1, Loss: 36840.5117\n",
            "Epoch 1, Loss: 36787.8320\n",
            "Epoch 1, Loss: 38925.0898\n",
            "Epoch 1, Loss: 36022.3906\n",
            "Epoch 1, Loss: 36974.0039\n",
            "Epoch 1, Loss: 34940.4570\n",
            "Epoch 1, Loss: 35388.4102\n",
            "Epoch 1, Loss: 36923.0938\n",
            "Epoch 1, Loss: 33977.7383\n",
            "Epoch 1, Loss: 34182.0703\n",
            "Epoch 1, Loss: 30974.1836\n",
            "Epoch 1, Loss: 33683.1055\n",
            "Epoch 1, Loss: 31887.1992\n",
            "Epoch 1, Loss: 31956.5332\n",
            "Epoch 1, Loss: 30402.9668\n",
            "Epoch 1, Loss: 28142.9238\n",
            "Epoch 1, Loss: 30398.2246\n",
            "Epoch 1, Loss: 27078.2676\n",
            "Epoch 1, Loss: 31755.4336\n",
            "Epoch 1, Loss: 28711.8848\n",
            "Epoch 1, Loss: 24465.6680\n",
            "Epoch 1, Loss: 24738.2773\n",
            "Epoch 1, Loss: 27455.0469\n",
            "Epoch 1, Loss: 25699.7363\n",
            "Epoch 1, Loss: 24739.0703\n",
            "Epoch 1, Loss: 24615.1855\n",
            "Epoch 1, Loss: 23627.3789\n",
            "Epoch 1, Loss: 24259.0312\n",
            "Epoch 1, Loss: 25315.1523\n",
            "Epoch 1, Loss: 24582.8867\n",
            "Epoch 1, Loss: 23961.5586\n",
            "Epoch 1, Loss: 21198.0703\n",
            "Epoch 1, Loss: 24275.0645\n",
            "Epoch 1, Loss: 22149.5605\n",
            "Epoch 1, Loss: 23221.5469\n",
            "Epoch 1, Loss: 21117.2090\n",
            "Epoch 1, Loss: 20779.0312\n",
            "Epoch 1, Loss: 20889.8457\n",
            "Epoch 1, Loss: 21206.4043\n",
            "Epoch 1, Loss: 20184.6777\n",
            "Epoch 1, Loss: 20164.4199\n",
            "Epoch 1, Loss: 20706.4395\n",
            "Epoch 1, Loss: 21554.3555\n",
            "Epoch 1, Loss: 18312.5410\n",
            "Epoch 1, Loss: 20206.0547\n",
            "Epoch 1, Loss: 19723.8027\n",
            "Epoch 1, Loss: 17878.9395\n",
            "Epoch 1, Loss: 19422.0742\n",
            "Epoch 1, Loss: 20798.8047\n",
            "Epoch 1, Loss: 19917.0312\n",
            "Epoch 1, Loss: 19011.2402\n",
            "Epoch 1, Loss: 19163.2871\n",
            "Epoch 1, Loss: 20508.9004\n",
            "Epoch 1, Loss: 19258.7773\n",
            "Epoch 1, Loss: 18575.8301\n",
            "Epoch 1, Loss: 19314.3965\n",
            "Epoch 1, Loss: 19854.7031\n",
            "Epoch 1, Loss: 18533.7422\n",
            "Epoch 1, Loss: 19390.0195\n",
            "Epoch 1, Loss: 17966.3066\n",
            "Epoch 1, Loss: 18909.9609\n",
            "Epoch 1, Loss: 19015.8066\n",
            "Epoch 1, Loss: 18026.7344\n",
            "Epoch 1, Loss: 18422.7676\n",
            "Epoch 1, Loss: 16673.7695\n",
            "Epoch 1, Loss: 18783.0020\n",
            "Epoch 1, Loss: 16662.5195\n",
            "Epoch 1, Loss: 18275.2051\n",
            "Epoch 1, Loss: 17728.2012\n",
            "Epoch 1, Loss: 18080.2617\n",
            "Epoch 1, Loss: 17651.7227\n",
            "Epoch 1, Loss: 16731.2832\n",
            "Epoch 1, Loss: 17505.0566\n",
            "Epoch 1, Loss: 16106.7471\n",
            "Epoch 1, Loss: 16531.4219\n",
            "Epoch 1, Loss: 17119.2578\n",
            "Epoch 1, Loss: 16424.2871\n",
            "Epoch 1, Loss: 18373.1504\n",
            "Epoch 1, Loss: 16948.0508\n",
            "Epoch 1, Loss: 17162.7441\n",
            "Epoch 1, Loss: 16079.7959\n",
            "Epoch 1, Loss: 17123.5312\n",
            "Epoch 1, Loss: 18059.2988\n",
            "Epoch 1, Loss: 16671.2598\n",
            "Epoch 1, Loss: 15633.7676\n",
            "Epoch 1, Loss: 16698.9785\n",
            "Epoch 1, Loss: 17805.6426\n",
            "Epoch 1, Loss: 16455.9082\n",
            "Epoch 1, Loss: 16966.8516\n",
            "Epoch 1, Loss: 15840.2490\n",
            "Epoch 1, Loss: 16552.9375\n",
            "Epoch 1, Loss: 16091.7021\n",
            "Epoch 1, Loss: 17194.3750\n",
            "Epoch 1, Loss: 16047.5264\n",
            "Epoch 1, Loss: 17316.3730\n",
            "Epoch 1, Loss: 16076.6709\n",
            "Epoch 1, Loss: 16740.8809\n",
            "Epoch 1, Loss: 15406.2705\n",
            "Epoch 1, Loss: 16456.2500\n",
            "Epoch 1, Loss: 16292.2891\n",
            "Epoch 1, Loss: 16121.5244\n",
            "Epoch 1, Loss: 15462.4678\n",
            "Epoch 1, Loss: 15973.5127\n",
            "Epoch 1, Loss: 17238.9961\n",
            "Epoch 1, Loss: 15091.7051\n",
            "Epoch 1, Loss: 15162.2217\n",
            "Epoch 1, Loss: 15855.9277\n",
            "Epoch 1, Loss: 16029.3242\n",
            "Epoch 1, Loss: 16586.6406\n",
            "Epoch 1, Loss: 16041.1846\n",
            "Epoch 1, Loss: 15851.4785\n",
            "Epoch 1, Loss: 14878.3486\n",
            "Epoch 1, Loss: 14642.7676\n",
            "Epoch 1, Loss: 15374.0547\n",
            "Epoch 1, Loss: 15698.1035\n",
            "Epoch 1, Loss: 14664.3018\n",
            "Epoch 1, Loss: 15927.4287\n",
            "Epoch 1, Loss: 15582.7656\n",
            "Epoch 1, Loss: 15231.4326\n",
            "Epoch 1, Loss: 15191.4102\n",
            "Epoch 1, Loss: 16254.4102\n",
            "Epoch 1, Loss: 15290.3760\n",
            "Epoch 1, Loss: 16903.9648\n",
            "Epoch 1, Loss: 16138.6045\n",
            "Epoch 1, Loss: 15977.6553\n",
            "Epoch 1, Loss: 6712.4307\n",
            "Epoch 2, Loss: 15384.9463\n",
            "Epoch 2, Loss: 16512.2051\n",
            "Epoch 2, Loss: 15089.6182\n",
            "Epoch 2, Loss: 15073.7451\n",
            "Epoch 2, Loss: 15175.9570\n",
            "Epoch 2, Loss: 14505.0713\n",
            "Epoch 2, Loss: 16073.1729\n",
            "Epoch 2, Loss: 16036.7734\n",
            "Epoch 2, Loss: 14981.2461\n",
            "Epoch 2, Loss: 15488.9443\n",
            "Epoch 2, Loss: 14966.8613\n",
            "Epoch 2, Loss: 16152.3428\n",
            "Epoch 2, Loss: 14606.3867\n",
            "Epoch 2, Loss: 15982.6113\n",
            "Epoch 2, Loss: 14595.8711\n",
            "Epoch 2, Loss: 15203.0332\n",
            "Epoch 2, Loss: 15087.3145\n",
            "Epoch 2, Loss: 15948.9209\n",
            "Epoch 2, Loss: 15047.4678\n",
            "Epoch 2, Loss: 15577.4092\n",
            "Epoch 2, Loss: 15059.7354\n",
            "Epoch 2, Loss: 15284.9912\n",
            "Epoch 2, Loss: 15224.4814\n",
            "Epoch 2, Loss: 14385.3125\n",
            "Epoch 2, Loss: 14252.4727\n",
            "Epoch 2, Loss: 15002.6318\n",
            "Epoch 2, Loss: 14468.0010\n",
            "Epoch 2, Loss: 13276.1895\n",
            "Epoch 2, Loss: 15458.6094\n",
            "Epoch 2, Loss: 14378.0908\n",
            "Epoch 2, Loss: 15149.9980\n",
            "Epoch 2, Loss: 16032.8467\n",
            "Epoch 2, Loss: 15503.4688\n",
            "Epoch 2, Loss: 14423.2754\n",
            "Epoch 2, Loss: 16124.7500\n",
            "Epoch 2, Loss: 14592.5840\n",
            "Epoch 2, Loss: 15215.6738\n",
            "Epoch 2, Loss: 14249.4727\n",
            "Epoch 2, Loss: 15443.1865\n",
            "Epoch 2, Loss: 14875.7754\n",
            "Epoch 2, Loss: 13846.0000\n",
            "Epoch 2, Loss: 14600.3613\n",
            "Epoch 2, Loss: 14094.7764\n",
            "Epoch 2, Loss: 13872.1201\n",
            "Epoch 2, Loss: 14245.5586\n",
            "Epoch 2, Loss: 14927.0234\n",
            "Epoch 2, Loss: 15040.9502\n",
            "Epoch 2, Loss: 14838.6045\n",
            "Epoch 2, Loss: 13792.5449\n",
            "Epoch 2, Loss: 13686.0234\n",
            "Epoch 2, Loss: 13716.3252\n",
            "Epoch 2, Loss: 14312.6143\n",
            "Epoch 2, Loss: 13918.1211\n",
            "Epoch 2, Loss: 14929.0654\n",
            "Epoch 2, Loss: 14245.9160\n",
            "Epoch 2, Loss: 14288.3828\n",
            "Epoch 2, Loss: 14528.5068\n",
            "Epoch 2, Loss: 14019.5518\n",
            "Epoch 2, Loss: 14454.7324\n",
            "Epoch 2, Loss: 14492.7129\n",
            "Epoch 2, Loss: 13231.5742\n",
            "Epoch 2, Loss: 13513.6494\n",
            "Epoch 2, Loss: 14335.8418\n",
            "Epoch 2, Loss: 13652.8447\n",
            "Epoch 2, Loss: 14226.0859\n",
            "Epoch 2, Loss: 13375.2217\n",
            "Epoch 2, Loss: 13864.1836\n",
            "Epoch 2, Loss: 14015.5742\n",
            "Epoch 2, Loss: 14890.2441\n",
            "Epoch 2, Loss: 14143.3135\n",
            "Epoch 2, Loss: 13442.8574\n",
            "Epoch 2, Loss: 13867.1367\n",
            "Epoch 2, Loss: 14331.0469\n",
            "Epoch 2, Loss: 12890.9551\n",
            "Epoch 2, Loss: 13611.3330\n",
            "Epoch 2, Loss: 13203.1953\n",
            "Epoch 2, Loss: 13316.4336\n",
            "Epoch 2, Loss: 13967.6982\n",
            "Epoch 2, Loss: 13874.6416\n",
            "Epoch 2, Loss: 13094.4238\n",
            "Epoch 2, Loss: 13047.8398\n",
            "Epoch 2, Loss: 12455.6855\n",
            "Epoch 2, Loss: 13913.0146\n",
            "Epoch 2, Loss: 13507.6865\n",
            "Epoch 2, Loss: 13305.6201\n",
            "Epoch 2, Loss: 12804.5098\n",
            "Epoch 2, Loss: 13211.1221\n",
            "Epoch 2, Loss: 14825.0566\n",
            "Epoch 2, Loss: 13207.0039\n",
            "Epoch 2, Loss: 13547.1914\n",
            "Epoch 2, Loss: 13865.4766\n",
            "Epoch 2, Loss: 14129.2305\n",
            "Epoch 2, Loss: 13053.4775\n",
            "Epoch 2, Loss: 13134.9531\n",
            "Epoch 2, Loss: 14100.7617\n",
            "Epoch 2, Loss: 12681.4326\n",
            "Epoch 2, Loss: 13582.4453\n",
            "Epoch 2, Loss: 13061.3037\n",
            "Epoch 2, Loss: 13225.1211\n",
            "Epoch 2, Loss: 12963.2178\n",
            "Epoch 2, Loss: 12889.6426\n",
            "Epoch 2, Loss: 12434.2539\n",
            "Epoch 2, Loss: 12938.1143\n",
            "Epoch 2, Loss: 12540.9541\n",
            "Epoch 2, Loss: 12957.8359\n",
            "Epoch 2, Loss: 13312.9004\n",
            "Epoch 2, Loss: 13143.2559\n",
            "Epoch 2, Loss: 12850.3721\n",
            "Epoch 2, Loss: 12406.1436\n",
            "Epoch 2, Loss: 12365.3789\n",
            "Epoch 2, Loss: 12207.2520\n",
            "Epoch 2, Loss: 13378.8936\n",
            "Epoch 2, Loss: 13403.9883\n",
            "Epoch 2, Loss: 11971.7402\n",
            "Epoch 2, Loss: 12488.9707\n",
            "Epoch 2, Loss: 12094.0391\n",
            "Epoch 2, Loss: 12943.0869\n",
            "Epoch 2, Loss: 12917.1953\n",
            "Epoch 2, Loss: 12024.7324\n",
            "Epoch 2, Loss: 11938.4092\n",
            "Epoch 2, Loss: 11360.8057\n",
            "Epoch 2, Loss: 11718.1650\n",
            "Epoch 2, Loss: 11515.5361\n",
            "Epoch 2, Loss: 11956.0879\n",
            "Epoch 2, Loss: 10908.2783\n",
            "Epoch 2, Loss: 11812.4043\n",
            "Epoch 2, Loss: 11336.5625\n",
            "Epoch 2, Loss: 11323.6738\n",
            "Epoch 2, Loss: 11262.0332\n",
            "Epoch 2, Loss: 10694.5186\n",
            "Epoch 2, Loss: 10660.3340\n",
            "Epoch 2, Loss: 10717.4023\n",
            "Epoch 2, Loss: 10888.5938\n",
            "Epoch 2, Loss: 10808.8672\n",
            "Epoch 2, Loss: 10351.8809\n",
            "Epoch 2, Loss: 10935.0498\n",
            "Epoch 2, Loss: 10582.7188\n",
            "Epoch 2, Loss: 10169.7529\n",
            "Epoch 2, Loss: 10155.4902\n",
            "Epoch 2, Loss: 10521.1035\n",
            "Epoch 2, Loss: 9665.2539\n",
            "Epoch 2, Loss: 9562.7246\n",
            "Epoch 2, Loss: 9957.3076\n",
            "Epoch 2, Loss: 9160.2383\n",
            "Epoch 2, Loss: 10122.0684\n",
            "Epoch 2, Loss: 9826.1260\n",
            "Epoch 2, Loss: 9836.5205\n",
            "Epoch 2, Loss: 9821.2383\n",
            "Epoch 2, Loss: 9804.9326\n",
            "Epoch 2, Loss: 9783.1846\n",
            "Epoch 2, Loss: 9932.0967\n",
            "Epoch 2, Loss: 9548.0439\n",
            "Epoch 2, Loss: 9875.7422\n",
            "Epoch 2, Loss: 9558.2412\n",
            "Epoch 2, Loss: 10291.7109\n",
            "Epoch 2, Loss: 9473.5156\n",
            "Epoch 2, Loss: 9230.3418\n",
            "Epoch 2, Loss: 8904.4590\n",
            "Epoch 2, Loss: 9393.5098\n",
            "Epoch 2, Loss: 9335.0215\n",
            "Epoch 2, Loss: 9162.2070\n",
            "Epoch 2, Loss: 8830.6826\n",
            "Epoch 2, Loss: 9051.4561\n",
            "Epoch 2, Loss: 8981.3135\n",
            "Epoch 2, Loss: 9464.8574\n",
            "Epoch 2, Loss: 9326.2432\n",
            "Epoch 2, Loss: 8760.5400\n",
            "Epoch 2, Loss: 8280.7881\n",
            "Epoch 2, Loss: 8547.5586\n",
            "Epoch 2, Loss: 8671.0703\n",
            "Epoch 2, Loss: 8555.9580\n",
            "Epoch 2, Loss: 8486.3389\n",
            "Epoch 2, Loss: 8515.5332\n",
            "Epoch 2, Loss: 8647.6387\n",
            "Epoch 2, Loss: 9316.4238\n",
            "Epoch 2, Loss: 9220.2656\n",
            "Epoch 2, Loss: 8442.7383\n",
            "Epoch 2, Loss: 8952.0850\n",
            "Epoch 2, Loss: 8916.3770\n",
            "Epoch 2, Loss: 8145.1328\n",
            "Epoch 2, Loss: 8646.0625\n",
            "Epoch 2, Loss: 9073.9053\n",
            "Epoch 2, Loss: 8479.3281\n",
            "Epoch 2, Loss: 8766.2266\n",
            "Epoch 2, Loss: 8773.5430\n",
            "Epoch 2, Loss: 8398.5176\n",
            "Epoch 2, Loss: 8426.4785\n",
            "Epoch 2, Loss: 8886.6074\n",
            "Epoch 2, Loss: 8727.5781\n",
            "Epoch 2, Loss: 8366.1846\n",
            "Epoch 2, Loss: 9245.7334\n",
            "Epoch 2, Loss: 8830.0576\n",
            "Epoch 2, Loss: 8934.7900\n",
            "Epoch 2, Loss: 8885.8926\n",
            "Epoch 2, Loss: 8406.0723\n",
            "Epoch 2, Loss: 8321.1426\n",
            "Epoch 2, Loss: 8262.5459\n",
            "Epoch 2, Loss: 8394.8896\n",
            "Epoch 2, Loss: 8139.3491\n",
            "Epoch 2, Loss: 8513.9199\n",
            "Epoch 2, Loss: 8341.1221\n",
            "Epoch 2, Loss: 8143.6182\n",
            "Epoch 2, Loss: 8894.4102\n",
            "Epoch 2, Loss: 8722.0762\n",
            "Epoch 2, Loss: 8577.2295\n",
            "Epoch 2, Loss: 8080.2832\n",
            "Epoch 2, Loss: 8116.7896\n",
            "Epoch 2, Loss: 8760.3232\n",
            "Epoch 2, Loss: 8336.7871\n",
            "Epoch 2, Loss: 8211.1465\n",
            "Epoch 2, Loss: 8073.2783\n",
            "Epoch 2, Loss: 8364.9385\n",
            "Epoch 2, Loss: 7819.6841\n",
            "Epoch 2, Loss: 8004.4365\n",
            "Epoch 2, Loss: 8071.4248\n",
            "Epoch 2, Loss: 8237.2568\n",
            "Epoch 2, Loss: 8334.9727\n",
            "Epoch 2, Loss: 7946.3081\n",
            "Epoch 2, Loss: 8225.8770\n",
            "Epoch 2, Loss: 8458.4961\n",
            "Epoch 2, Loss: 7834.4766\n",
            "Epoch 2, Loss: 8532.5928\n",
            "Epoch 2, Loss: 8059.6279\n",
            "Epoch 2, Loss: 7684.8867\n",
            "Epoch 2, Loss: 8027.8193\n",
            "Epoch 2, Loss: 8346.9531\n",
            "Epoch 2, Loss: 8233.7461\n",
            "Epoch 2, Loss: 8023.5381\n",
            "Epoch 2, Loss: 7832.6636\n",
            "Epoch 2, Loss: 7874.8818\n",
            "Epoch 2, Loss: 3367.2146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # Change the number of epochs as needed\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        inputs = data.float()\n",
        "        print(\"Input shape: (barch | channel | height and width)\", inputs.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaZC29TPm0er",
        "outputId": "cc11a843-9953-47be-8df8-e8f0f8bafed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([26, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([64, 1, 64, 64])\n",
            "Input shape: (barch | channel | height and width) torch.Size([26, 1, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Beta For Test"
      ],
      "metadata": {
        "id": "uvLoQsZcamTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Loss Functions\n",
        "'''\n",
        "\n",
        "def kl_divergence_stdnorm(z_mean, z_log_sigma):\n",
        "\n",
        "  kl = -0.5*K.mean(K.sum(1 + 2*z_log_sigma - K.square(z_mean) - K.exp(2*z_log_sigma), axis=1))\n",
        "  return kl\n",
        "\n",
        "def reconstruction_ll(x_true, x_prob_logit):\n",
        "\n",
        "  x_true = K.batch_flatten(x_true)\n",
        "  x_prob_logit = K.batch_flatten(x_prob_logit)\n",
        "\n",
        "  ce = K.binary_crossentropy(x_true, x_prob_logit, from_logits=True)\n",
        "  ce = K.sum(ce, axis=1)\n",
        "  ce = K.mean(ce)\n",
        "\n",
        "  return ce\n",
        "def beta_vae_loss(x_true, z_mean, z_log_sigma, x_rec_logit, beta=4.0):\n",
        "\n",
        "  reconstruction_l = reconstruction_ll(x_true, x_rec_logit)\n",
        "  kl_divergence = kl_divergence_stdnorm(z_mean, z_log_sigma)\n",
        "\n",
        "  beta_vae_l = reconstruction_l + beta*kl_divergence\n",
        "\n",
        "  return beta_vae_l, reconstruction_l, kl_divergence\n",
        "\n",
        "\n",
        "'''\n",
        "Utility Functions\n",
        "'''\n",
        "\n",
        "def norm_sampling(mean, log_stdev):\n",
        "\n",
        "  epsilon = K.random_normal(shape=K.shape(mean))\n",
        "\n",
        "  return mean + K.exp(log_stdev) * epsilon\n",
        "\n",
        "def permute_dims(z):\n",
        "\n",
        "  shuffled_features = [K.expand_dims(tf.random.shuffle(z[:,i]), axis=-1) for i in range(K.int_shape(z)[1])]\n",
        "  shuffled = K.concatenate(shuffled_features, axis=-1)\n",
        "\n",
        "  return shuffled\n"
      ],
      "metadata": {
        "id": "cgF89rsVaogI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Model):\n",
        "\n",
        "  def __init__(self, latent_dims):\n",
        "    super(Encoder, self).__init__(name='encoder')\n",
        "\n",
        "    self.latent_dims = latent_dims\n",
        "\n",
        "    self.reshape_input = Reshape((64,64,1), input_shape=(64,64))\n",
        "    self.hidden_layers = [Conv2D(32, kernel_size=(4,4), strides=(2,2), activation='relu', padding='same') for _ in range(2)]\n",
        "    self.hidden_layers += [Conv2D(64, kernel_size=(4,4), strides=(2,2), activation='relu', padding='same') for _ in range(2)]\n",
        "    self.hidden_layers += [Flatten(), Dense(128)]\n",
        "\n",
        "    self.means = Dense(self.latent_dims)\n",
        "    self.log_stdevs = Dense(self.latent_dims)\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    x = self.reshape_input(x)\n",
        "    for h in self.hidden_layers:\n",
        "      x = h(x)\n",
        "\n",
        "    return self.means(x), self.log_stdevs(x)\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(Model):\n",
        "\n",
        "  def __init__(self, latent_dims):\n",
        "    super(Decoder, self).__init__(name='decoder')\n",
        "\n",
        "    self.latent_dims = latent_dims\n",
        "\n",
        "    self.hidden_layers = [\n",
        "      Dense(128, activation='relu', input_shape=(self.latent_dims,)),\n",
        "      Dense(4*4*64, activation='relu'),\n",
        "      Reshape((4, 4, 64)),\n",
        "      Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), activation='relu', padding='same'),\n",
        "      Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), activation='relu', padding='same'),\n",
        "      Conv2DTranspose(32, kernel_size=(4,4), strides=(2,2), activation='relu', padding='same'),\n",
        "      Conv2DTranspose(1, kernel_size=(4,4), strides=(2,2), padding='same'),\n",
        "      Reshape((64, 64))\n",
        "    ]\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    for h in self.hidden_layers:\n",
        "      x = h(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "80J9pJvh3o6f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BetaVAE():\n",
        "\n",
        "  def __init__(self, latent_dims=10, beta=4.0):\n",
        "    super(BetaVAE, self).__init__()\n",
        "\n",
        "    self.beta = beta\n",
        "    self.latent_dims = latent_dims\n",
        "\n",
        "    self.encoder = Encoder(latent_dims)\n",
        "    self.decoder = Decoder(latent_dims)\n",
        "\n",
        "  def fit(self, X, batch_size=64):\n",
        "\n",
        "    X_train, X_val = train_test_split(X, train_size=0.75, test_size=0.25, random_state=38, shuffle=True)\n",
        "\n",
        "    X_train_ds = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "    X_train_ds = X_train_ds.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    beta_vae_optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "    iterations_per_epoch = X_train.shape[0]/batch_size\n",
        "    iterations = 3e5\n",
        "    n_epochs = int(iterations/iterations_per_epoch)\n",
        "\n",
        "    for epoch in range(0, n_epochs):\n",
        "      print(\"Epoch %d/%d\" % (epoch+1, n_epochs))\n",
        "\n",
        "      bar = Progbar(X_train.shape[0], stateful_metrics=[\"val_loss\"], verbose=1)\n",
        "\n",
        "      last_step = int(np.ceil(X_train.shape[0]/batch_size)) - 1\n",
        "      for step, x_batch in enumerate(X_train_ds):\n",
        "        beta_vae_l, rec_l, kl_div = self._train_step(x_batch, beta_vae_optimizer)\n",
        "\n",
        "        if step == last_step:\n",
        "          val_beta_vae_l, val_rec_l, val_kl_div = self._evaluate(X_val)\n",
        "          bar.add(x_batch.shape[0],\n",
        "                  values=[\n",
        "                    (\"loss\", beta_vae_l),\n",
        "                    (\"rec_loss\", rec_l),\n",
        "                    (\"kl_div\", kl_div),\n",
        "                    (\"val_loss\", val_beta_vae_l),\n",
        "                    (\"val_rec_loss\", val_rec_l),\n",
        "                    (\"val_kl_div\", val_kl_div),\n",
        "                  ])\n",
        "\n",
        "        else:\n",
        "          bar.add(x_batch.shape[0],\n",
        "                  values=[\n",
        "                    (\"loss\", beta_vae_l),\n",
        "                    (\"rec_loss\", rec_l),\n",
        "                    (\"kl_div\", kl_div),\n",
        "                  ])\n",
        "\n",
        "  @tf.function\n",
        "  def _train_step(self, X, optimizer):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      z_mean, z_stdev = self.encoder(X)\n",
        "      samples = norm_sampling(z_mean, z_stdev)\n",
        "      z_rec = self.decoder(samples)\n",
        "\n",
        "      beta_vae_l, rec_l, kl_div = beta_vae_loss(X, z_mean, z_stdev, z_rec, self.beta)\n",
        "\n",
        "    # optimize VAE\n",
        "    variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "    grad = tape.gradient(beta_vae_l, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(grad, variables))\n",
        "\n",
        "    return beta_vae_l, rec_l, kl_div\n",
        "\n",
        "  @tf.function\n",
        "  def _evaluate(self, X):\n",
        "\n",
        "    z_mean, z_stdev = self.encoder(X)\n",
        "    samples = norm_sampling(z_mean, z_stdev)\n",
        "    z_rec = self.decoder(samples)\n",
        "\n",
        "    beta_vae_l, rec_l, kl_div = beta_vae_loss(X, z_mean, z_stdev, z_rec, self.beta)\n",
        "\n",
        "    return beta_vae_l, rec_l, kl_div"
      ],
      "metadata": {
        "id": "sqolUcFZbAKg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-2. Implementation VAE ( Beta )\n",
        "* Optimizer  Adam\n",
        "* with β1 = 0.90, β2 = 0.99\n",
        "* Leaning rate 0.0001\n",
        "* Reconstruction loss Bernoull"
      ],
      "metadata": {
        "id": "p3XObdiZcfkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BetaVAE(nn.Module):\n",
        "    def __init__(self, beta=1.0):\n",
        "        super(BetaVAE, self).__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 256, kernel_size=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 20)  # 2 * 10 for mean and logvar\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(10, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (256, 2, 2)),\n",
        "            nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu_logvar = self.encoder(x)\n",
        "        mu, logvar = torch.split(mu_logvar, 10, dim=1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decoder(z)\n",
        "\n",
        "        # Compute the reconstruction loss and the KL divergence with the beta factor\n",
        "        reconstruction_loss = F.binary_cross_entropy(x_recon, x, reduction='sum')\n",
        "        kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        # Total loss with the beta factor\n",
        "        loss = reconstruction_loss + self.beta * kl_divergence\n",
        "\n",
        "        return x_recon, mu, logvar, loss\n",
        "\n",
        "# Instantiate the model and set up the optimizer\n",
        "beta_vae = BetaVAE(beta=1.0)\n",
        "optimizer = optim.Adam(beta_vae.parameters(), lr=0.0001, betas=(0.90, 0.99))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(2):  # Change the number of epochs as needed\n",
        "    beta_vae.train()\n",
        "    for data in train_loader:\n",
        "        inputs = data.float()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        recon_batch, mu, logvar, loss = beta_vae(inputs)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"Epoch {}, Loss: {:.4f}\".format(epoch + 1, loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDF4s9zVchzP",
        "outputId": "857c7f72-b646-4936-a015-51990e6b1ff2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 155842.7500\n",
            "Epoch 1, Loss: 155949.5469\n",
            "Epoch 1, Loss: 155797.6875\n",
            "Epoch 1, Loss: 155590.2500\n",
            "Epoch 1, Loss: 155356.2969\n",
            "Epoch 1, Loss: 155547.5938\n",
            "Epoch 1, Loss: 155371.6562\n",
            "Epoch 1, Loss: 155357.4531\n",
            "Epoch 1, Loss: 155043.5312\n",
            "Epoch 1, Loss: 155252.4219\n",
            "Epoch 1, Loss: 155111.6875\n",
            "Epoch 1, Loss: 154860.8594\n",
            "Epoch 1, Loss: 154564.0312\n",
            "Epoch 1, Loss: 154555.6875\n",
            "Epoch 1, Loss: 154348.1406\n",
            "Epoch 1, Loss: 154239.6250\n",
            "Epoch 1, Loss: 154339.8594\n",
            "Epoch 1, Loss: 153813.6406\n",
            "Epoch 1, Loss: 153790.4219\n",
            "Epoch 1, Loss: 153519.4844\n",
            "Epoch 1, Loss: 153496.7812\n",
            "Epoch 1, Loss: 152791.3125\n",
            "Epoch 1, Loss: 152693.3438\n",
            "Epoch 1, Loss: 152259.1094\n",
            "Epoch 1, Loss: 151806.5000\n",
            "Epoch 1, Loss: 151066.5156\n",
            "Epoch 1, Loss: 150532.8281\n",
            "Epoch 1, Loss: 149473.1406\n",
            "Epoch 1, Loss: 149202.9531\n",
            "Epoch 1, Loss: 146973.3750\n",
            "Epoch 1, Loss: 146488.2031\n",
            "Epoch 1, Loss: 144411.2188\n",
            "Epoch 1, Loss: 142339.2188\n",
            "Epoch 1, Loss: 140985.5156\n",
            "Epoch 1, Loss: 137807.2812\n",
            "Epoch 1, Loss: 134441.0312\n",
            "Epoch 1, Loss: 131069.5469\n",
            "Epoch 1, Loss: 126527.7266\n",
            "Epoch 1, Loss: 121661.7109\n",
            "Epoch 1, Loss: 115636.5625\n",
            "Epoch 1, Loss: 111058.3125\n",
            "Epoch 1, Loss: 105027.3359\n",
            "Epoch 1, Loss: 99262.9688\n",
            "Epoch 1, Loss: 94556.3906\n",
            "Epoch 1, Loss: 87652.8203\n",
            "Epoch 1, Loss: 91838.6016\n",
            "Epoch 1, Loss: 87941.1094\n",
            "Epoch 1, Loss: 89600.5312\n",
            "Epoch 1, Loss: 95646.1250\n",
            "Epoch 1, Loss: 85689.4297\n",
            "Epoch 1, Loss: 87880.0156\n",
            "Epoch 1, Loss: 78924.8594\n",
            "Epoch 1, Loss: 90443.7266\n",
            "Epoch 1, Loss: 79449.7188\n",
            "Epoch 1, Loss: 85582.9922\n",
            "Epoch 1, Loss: 83604.2891\n",
            "Epoch 1, Loss: 80676.4453\n",
            "Epoch 1, Loss: 83021.8047\n",
            "Epoch 1, Loss: 80217.0234\n",
            "Epoch 1, Loss: 79968.2344\n",
            "Epoch 1, Loss: 80979.2266\n",
            "Epoch 1, Loss: 80089.4453\n",
            "Epoch 1, Loss: 79529.8828\n",
            "Epoch 1, Loss: 77032.1641\n",
            "Epoch 1, Loss: 76261.9062\n",
            "Epoch 1, Loss: 79019.9922\n",
            "Epoch 1, Loss: 78672.0469\n",
            "Epoch 1, Loss: 78331.4844\n",
            "Epoch 1, Loss: 74357.5156\n",
            "Epoch 1, Loss: 74618.8203\n",
            "Epoch 1, Loss: 75984.2109\n",
            "Epoch 1, Loss: 73861.9453\n",
            "Epoch 1, Loss: 70371.6953\n",
            "Epoch 1, Loss: 74385.5078\n",
            "Epoch 1, Loss: 74007.6172\n",
            "Epoch 1, Loss: 69755.8906\n",
            "Epoch 1, Loss: 72878.4844\n",
            "Epoch 1, Loss: 70593.7031\n",
            "Epoch 1, Loss: 70514.0312\n",
            "Epoch 1, Loss: 68900.5859\n",
            "Epoch 1, Loss: 70638.3047\n",
            "Epoch 1, Loss: 72048.7734\n",
            "Epoch 1, Loss: 71110.5547\n",
            "Epoch 1, Loss: 71026.7969\n",
            "Epoch 1, Loss: 68215.8125\n",
            "Epoch 1, Loss: 66850.3125\n",
            "Epoch 1, Loss: 67038.4609\n",
            "Epoch 1, Loss: 66068.2578\n",
            "Epoch 1, Loss: 62120.3672\n",
            "Epoch 1, Loss: 65115.7227\n",
            "Epoch 1, Loss: 65508.4922\n",
            "Epoch 1, Loss: 59396.2891\n",
            "Epoch 1, Loss: 65360.6680\n",
            "Epoch 1, Loss: 61527.7930\n",
            "Epoch 1, Loss: 62351.0859\n",
            "Epoch 1, Loss: 59815.1367\n",
            "Epoch 1, Loss: 59543.2812\n",
            "Epoch 1, Loss: 62518.1953\n",
            "Epoch 1, Loss: 54598.1055\n",
            "Epoch 1, Loss: 61967.9219\n",
            "Epoch 1, Loss: 57173.6992\n",
            "Epoch 1, Loss: 55728.6328\n",
            "Epoch 1, Loss: 55155.5508\n",
            "Epoch 1, Loss: 55622.7148\n",
            "Epoch 1, Loss: 55779.9883\n",
            "Epoch 1, Loss: 59716.0039\n",
            "Epoch 1, Loss: 53002.6211\n",
            "Epoch 1, Loss: 55947.4531\n",
            "Epoch 1, Loss: 52745.4102\n",
            "Epoch 1, Loss: 53644.5781\n",
            "Epoch 1, Loss: 51523.8164\n",
            "Epoch 1, Loss: 52080.9375\n",
            "Epoch 1, Loss: 50820.9023\n",
            "Epoch 1, Loss: 51525.8945\n",
            "Epoch 1, Loss: 48869.4844\n",
            "Epoch 1, Loss: 49186.9414\n",
            "Epoch 1, Loss: 48743.1914\n",
            "Epoch 1, Loss: 47638.5430\n",
            "Epoch 1, Loss: 48167.5703\n",
            "Epoch 1, Loss: 51481.0039\n",
            "Epoch 1, Loss: 46960.6328\n",
            "Epoch 1, Loss: 50474.6641\n",
            "Epoch 1, Loss: 46755.0312\n",
            "Epoch 1, Loss: 47551.8164\n",
            "Epoch 1, Loss: 46204.5625\n",
            "Epoch 1, Loss: 43565.7383\n",
            "Epoch 1, Loss: 47803.0273\n",
            "Epoch 1, Loss: 46547.2930\n",
            "Epoch 1, Loss: 46872.3398\n",
            "Epoch 1, Loss: 48669.4727\n",
            "Epoch 1, Loss: 49335.4883\n",
            "Epoch 1, Loss: 45186.6914\n",
            "Epoch 1, Loss: 43189.1406\n",
            "Epoch 1, Loss: 45497.1758\n",
            "Epoch 1, Loss: 41073.8320\n",
            "Epoch 1, Loss: 44239.0039\n",
            "Epoch 1, Loss: 47166.3398\n",
            "Epoch 1, Loss: 49719.4297\n",
            "Epoch 1, Loss: 41284.1289\n",
            "Epoch 1, Loss: 40621.5781\n",
            "Epoch 1, Loss: 41707.2656\n",
            "Epoch 1, Loss: 44673.2852\n",
            "Epoch 1, Loss: 46907.5352\n",
            "Epoch 1, Loss: 44373.6797\n",
            "Epoch 1, Loss: 40370.0117\n",
            "Epoch 1, Loss: 42785.8516\n",
            "Epoch 1, Loss: 43943.0078\n",
            "Epoch 1, Loss: 42366.7148\n",
            "Epoch 1, Loss: 43734.2539\n",
            "Epoch 1, Loss: 39932.4766\n",
            "Epoch 1, Loss: 40218.8047\n",
            "Epoch 1, Loss: 44724.5234\n",
            "Epoch 1, Loss: 37449.5156\n",
            "Epoch 1, Loss: 41095.2969\n",
            "Epoch 1, Loss: 43463.3438\n",
            "Epoch 1, Loss: 44531.0117\n",
            "Epoch 1, Loss: 43923.5586\n",
            "Epoch 1, Loss: 45732.6445\n",
            "Epoch 1, Loss: 41237.5195\n",
            "Epoch 1, Loss: 42212.5586\n",
            "Epoch 1, Loss: 40877.3789\n",
            "Epoch 1, Loss: 41274.5820\n",
            "Epoch 1, Loss: 40170.9609\n",
            "Epoch 1, Loss: 41876.9102\n",
            "Epoch 1, Loss: 42917.5938\n",
            "Epoch 1, Loss: 39657.4023\n",
            "Epoch 1, Loss: 44275.7227\n",
            "Epoch 1, Loss: 44417.7070\n",
            "Epoch 1, Loss: 41125.9844\n",
            "Epoch 1, Loss: 40164.3164\n",
            "Epoch 1, Loss: 41440.9180\n",
            "Epoch 1, Loss: 41156.3164\n",
            "Epoch 1, Loss: 41518.3398\n",
            "Epoch 1, Loss: 40725.9961\n",
            "Epoch 1, Loss: 40680.4062\n",
            "Epoch 1, Loss: 42487.4492\n",
            "Epoch 1, Loss: 40067.2578\n",
            "Epoch 1, Loss: 40967.4766\n",
            "Epoch 1, Loss: 38065.6211\n",
            "Epoch 1, Loss: 41549.3438\n",
            "Epoch 1, Loss: 38645.6758\n",
            "Epoch 1, Loss: 38593.0117\n",
            "Epoch 1, Loss: 41670.8086\n",
            "Epoch 1, Loss: 40498.0859\n",
            "Epoch 1, Loss: 43057.7734\n",
            "Epoch 1, Loss: 42538.0234\n",
            "Epoch 1, Loss: 43121.7773\n",
            "Epoch 1, Loss: 38410.2773\n",
            "Epoch 1, Loss: 35613.1367\n",
            "Epoch 1, Loss: 37826.6289\n",
            "Epoch 1, Loss: 38892.9648\n",
            "Epoch 1, Loss: 41950.2773\n",
            "Epoch 1, Loss: 40061.3320\n",
            "Epoch 1, Loss: 37019.5391\n",
            "Epoch 1, Loss: 38734.4375\n",
            "Epoch 1, Loss: 41909.1875\n",
            "Epoch 1, Loss: 39396.0547\n",
            "Epoch 1, Loss: 41935.5000\n",
            "Epoch 1, Loss: 40336.4727\n",
            "Epoch 1, Loss: 35140.7227\n",
            "Epoch 1, Loss: 39177.1914\n",
            "Epoch 1, Loss: 38411.1133\n",
            "Epoch 1, Loss: 40575.1602\n",
            "Epoch 1, Loss: 41781.3203\n",
            "Epoch 1, Loss: 38389.3789\n",
            "Epoch 1, Loss: 40568.9922\n",
            "Epoch 1, Loss: 36492.5586\n",
            "Epoch 1, Loss: 41964.9961\n",
            "Epoch 1, Loss: 38753.8125\n",
            "Epoch 1, Loss: 40495.6484\n",
            "Epoch 1, Loss: 40971.6367\n",
            "Epoch 1, Loss: 37693.9453\n",
            "Epoch 1, Loss: 40990.3125\n",
            "Epoch 1, Loss: 34809.6406\n",
            "Epoch 1, Loss: 39070.4492\n",
            "Epoch 1, Loss: 36093.6016\n",
            "Epoch 1, Loss: 40020.8984\n",
            "Epoch 1, Loss: 39515.9062\n",
            "Epoch 1, Loss: 39995.7852\n",
            "Epoch 1, Loss: 34796.9961\n",
            "Epoch 1, Loss: 36405.0000\n",
            "Epoch 1, Loss: 36309.6523\n",
            "Epoch 1, Loss: 36607.5469\n",
            "Epoch 1, Loss: 40084.9141\n",
            "Epoch 1, Loss: 34730.9336\n",
            "Epoch 1, Loss: 36269.6055\n",
            "Epoch 1, Loss: 35400.8633\n",
            "Epoch 1, Loss: 38052.3906\n",
            "Epoch 1, Loss: 41288.3164\n",
            "Epoch 1, Loss: 38706.4102\n",
            "Epoch 1, Loss: 14791.1104\n",
            "Epoch 2, Loss: 37274.9375\n",
            "Epoch 2, Loss: 35769.2891\n",
            "Epoch 2, Loss: 39511.0273\n",
            "Epoch 2, Loss: 36734.2812\n",
            "Epoch 2, Loss: 38914.2891\n",
            "Epoch 2, Loss: 40018.9961\n",
            "Epoch 2, Loss: 42337.0898\n",
            "Epoch 2, Loss: 39921.8594\n",
            "Epoch 2, Loss: 39352.8984\n",
            "Epoch 2, Loss: 39723.9414\n",
            "Epoch 2, Loss: 39040.7852\n",
            "Epoch 2, Loss: 35422.8672\n",
            "Epoch 2, Loss: 34405.4023\n",
            "Epoch 2, Loss: 37891.7500\n",
            "Epoch 2, Loss: 35050.8516\n",
            "Epoch 2, Loss: 40991.1016\n",
            "Epoch 2, Loss: 35613.9766\n",
            "Epoch 2, Loss: 38978.3398\n",
            "Epoch 2, Loss: 39237.5391\n",
            "Epoch 2, Loss: 35808.0117\n",
            "Epoch 2, Loss: 37022.7891\n",
            "Epoch 2, Loss: 39477.5781\n",
            "Epoch 2, Loss: 36807.6836\n",
            "Epoch 2, Loss: 37366.5469\n",
            "Epoch 2, Loss: 38497.7656\n",
            "Epoch 2, Loss: 38831.6016\n",
            "Epoch 2, Loss: 35144.0352\n",
            "Epoch 2, Loss: 35958.8086\n",
            "Epoch 2, Loss: 35580.5820\n",
            "Epoch 2, Loss: 38027.9766\n",
            "Epoch 2, Loss: 33531.2500\n",
            "Epoch 2, Loss: 36181.6211\n",
            "Epoch 2, Loss: 35288.4180\n",
            "Epoch 2, Loss: 35394.8242\n",
            "Epoch 2, Loss: 36709.6875\n",
            "Epoch 2, Loss: 36353.8594\n",
            "Epoch 2, Loss: 40874.9062\n",
            "Epoch 2, Loss: 35724.6914\n",
            "Epoch 2, Loss: 36805.0273\n",
            "Epoch 2, Loss: 38732.2695\n",
            "Epoch 2, Loss: 39939.9531\n",
            "Epoch 2, Loss: 38608.7031\n",
            "Epoch 2, Loss: 40064.2734\n",
            "Epoch 2, Loss: 37228.8516\n",
            "Epoch 2, Loss: 40995.5352\n",
            "Epoch 2, Loss: 37677.3633\n",
            "Epoch 2, Loss: 37440.1211\n",
            "Epoch 2, Loss: 37824.2578\n",
            "Epoch 2, Loss: 39090.0000\n",
            "Epoch 2, Loss: 34898.0703\n",
            "Epoch 2, Loss: 39736.6992\n",
            "Epoch 2, Loss: 35602.5977\n",
            "Epoch 2, Loss: 39791.9492\n",
            "Epoch 2, Loss: 39007.1875\n",
            "Epoch 2, Loss: 36903.2578\n",
            "Epoch 2, Loss: 38503.6875\n",
            "Epoch 2, Loss: 36311.4219\n",
            "Epoch 2, Loss: 37555.0234\n",
            "Epoch 2, Loss: 39202.0000\n",
            "Epoch 2, Loss: 41644.7383\n",
            "Epoch 2, Loss: 35600.4609\n",
            "Epoch 2, Loss: 38006.3008\n",
            "Epoch 2, Loss: 36984.5430\n",
            "Epoch 2, Loss: 37746.3867\n",
            "Epoch 2, Loss: 37925.6172\n",
            "Epoch 2, Loss: 34712.3750\n",
            "Epoch 2, Loss: 40526.1953\n",
            "Epoch 2, Loss: 35353.5430\n",
            "Epoch 2, Loss: 36120.5430\n",
            "Epoch 2, Loss: 33260.8086\n",
            "Epoch 2, Loss: 39137.6836\n",
            "Epoch 2, Loss: 39146.8672\n",
            "Epoch 2, Loss: 35810.5703\n",
            "Epoch 2, Loss: 37035.9453\n",
            "Epoch 2, Loss: 36766.6211\n",
            "Epoch 2, Loss: 34896.7422\n",
            "Epoch 2, Loss: 34442.7188\n",
            "Epoch 2, Loss: 39442.1133\n",
            "Epoch 2, Loss: 37452.0586\n",
            "Epoch 2, Loss: 35197.5859\n",
            "Epoch 2, Loss: 36560.0703\n",
            "Epoch 2, Loss: 39732.1172\n",
            "Epoch 2, Loss: 39572.3047\n",
            "Epoch 2, Loss: 36424.1367\n",
            "Epoch 2, Loss: 37798.6484\n",
            "Epoch 2, Loss: 38812.1758\n",
            "Epoch 2, Loss: 38727.9219\n",
            "Epoch 2, Loss: 36692.3555\n",
            "Epoch 2, Loss: 37249.4727\n",
            "Epoch 2, Loss: 36392.4805\n",
            "Epoch 2, Loss: 38293.3516\n",
            "Epoch 2, Loss: 34398.0352\n",
            "Epoch 2, Loss: 37738.8438\n",
            "Epoch 2, Loss: 37378.3594\n",
            "Epoch 2, Loss: 35059.0039\n",
            "Epoch 2, Loss: 38462.3672\n",
            "Epoch 2, Loss: 37833.2109\n",
            "Epoch 2, Loss: 37989.0742\n",
            "Epoch 2, Loss: 34937.4180\n",
            "Epoch 2, Loss: 38320.1836\n",
            "Epoch 2, Loss: 40482.4297\n",
            "Epoch 2, Loss: 37092.3828\n",
            "Epoch 2, Loss: 35559.0703\n",
            "Epoch 2, Loss: 37788.8047\n",
            "Epoch 2, Loss: 39118.9648\n",
            "Epoch 2, Loss: 33257.8477\n",
            "Epoch 2, Loss: 37539.4922\n",
            "Epoch 2, Loss: 36575.0156\n",
            "Epoch 2, Loss: 37573.1406\n",
            "Epoch 2, Loss: 39555.6562\n",
            "Epoch 2, Loss: 33081.5000\n",
            "Epoch 2, Loss: 37786.5273\n",
            "Epoch 2, Loss: 38411.8906\n",
            "Epoch 2, Loss: 35440.5352\n",
            "Epoch 2, Loss: 35770.1016\n",
            "Epoch 2, Loss: 36962.6250\n",
            "Epoch 2, Loss: 38367.3633\n",
            "Epoch 2, Loss: 36967.0195\n",
            "Epoch 2, Loss: 37403.4492\n",
            "Epoch 2, Loss: 35791.3711\n",
            "Epoch 2, Loss: 36667.4062\n",
            "Epoch 2, Loss: 38446.4648\n",
            "Epoch 2, Loss: 34421.1641\n",
            "Epoch 2, Loss: 37608.3359\n",
            "Epoch 2, Loss: 38099.3711\n",
            "Epoch 2, Loss: 37280.7578\n",
            "Epoch 2, Loss: 38738.9570\n",
            "Epoch 2, Loss: 36643.4688\n",
            "Epoch 2, Loss: 35471.7070\n",
            "Epoch 2, Loss: 40713.0742\n",
            "Epoch 2, Loss: 37834.0469\n",
            "Epoch 2, Loss: 36819.1289\n",
            "Epoch 2, Loss: 39164.9062\n",
            "Epoch 2, Loss: 40745.5820\n",
            "Epoch 2, Loss: 35881.9219\n",
            "Epoch 2, Loss: 35975.0859\n",
            "Epoch 2, Loss: 36049.8477\n",
            "Epoch 2, Loss: 36484.1719\n",
            "Epoch 2, Loss: 36595.2852\n",
            "Epoch 2, Loss: 37348.3672\n",
            "Epoch 2, Loss: 35891.2461\n",
            "Epoch 2, Loss: 34691.0000\n",
            "Epoch 2, Loss: 39748.2734\n",
            "Epoch 2, Loss: 37549.6562\n",
            "Epoch 2, Loss: 39528.6367\n",
            "Epoch 2, Loss: 37486.7773\n",
            "Epoch 2, Loss: 38050.2969\n",
            "Epoch 2, Loss: 36656.0859\n",
            "Epoch 2, Loss: 35958.4805\n",
            "Epoch 2, Loss: 37111.6992\n",
            "Epoch 2, Loss: 36259.3281\n",
            "Epoch 2, Loss: 35692.5391\n",
            "Epoch 2, Loss: 37416.9961\n",
            "Epoch 2, Loss: 36811.5938\n",
            "Epoch 2, Loss: 37853.6211\n",
            "Epoch 2, Loss: 39313.6328\n",
            "Epoch 2, Loss: 35316.1055\n",
            "Epoch 2, Loss: 38947.4883\n",
            "Epoch 2, Loss: 38618.4336\n",
            "Epoch 2, Loss: 34737.4570\n",
            "Epoch 2, Loss: 36883.6523\n",
            "Epoch 2, Loss: 39057.7422\n",
            "Epoch 2, Loss: 40426.6211\n",
            "Epoch 2, Loss: 35773.5156\n",
            "Epoch 2, Loss: 38022.6250\n",
            "Epoch 2, Loss: 34987.5195\n",
            "Epoch 2, Loss: 40162.9609\n",
            "Epoch 2, Loss: 34908.3242\n",
            "Epoch 2, Loss: 36995.2656\n",
            "Epoch 2, Loss: 39418.1680\n",
            "Epoch 2, Loss: 37464.2383\n",
            "Epoch 2, Loss: 34883.0391\n",
            "Epoch 2, Loss: 38693.7109\n",
            "Epoch 2, Loss: 36908.3711\n",
            "Epoch 2, Loss: 34349.5625\n",
            "Epoch 2, Loss: 33141.3164\n",
            "Epoch 2, Loss: 37768.9570\n",
            "Epoch 2, Loss: 36046.8086\n",
            "Epoch 2, Loss: 32269.7559\n",
            "Epoch 2, Loss: 36538.6914\n",
            "Epoch 2, Loss: 38244.2266\n",
            "Epoch 2, Loss: 36302.7969\n",
            "Epoch 2, Loss: 36904.4883\n",
            "Epoch 2, Loss: 42427.7695\n",
            "Epoch 2, Loss: 37522.6914\n",
            "Epoch 2, Loss: 37823.5117\n",
            "Epoch 2, Loss: 39177.0156\n",
            "Epoch 2, Loss: 37831.8516\n",
            "Epoch 2, Loss: 35609.6016\n",
            "Epoch 2, Loss: 33561.6211\n",
            "Epoch 2, Loss: 32881.0664\n",
            "Epoch 2, Loss: 35560.6758\n",
            "Epoch 2, Loss: 39781.2852\n",
            "Epoch 2, Loss: 37358.3750\n",
            "Epoch 2, Loss: 33943.9531\n",
            "Epoch 2, Loss: 37599.2461\n",
            "Epoch 2, Loss: 38886.4219\n",
            "Epoch 2, Loss: 38641.8320\n",
            "Epoch 2, Loss: 32619.5371\n",
            "Epoch 2, Loss: 37830.0664\n",
            "Epoch 2, Loss: 35637.4609\n",
            "Epoch 2, Loss: 34892.1836\n",
            "Epoch 2, Loss: 34623.6992\n",
            "Epoch 2, Loss: 35091.6914\n",
            "Epoch 2, Loss: 35230.5742\n",
            "Epoch 2, Loss: 37433.7266\n",
            "Epoch 2, Loss: 38311.4414\n",
            "Epoch 2, Loss: 33518.8086\n",
            "Epoch 2, Loss: 34793.1055\n",
            "Epoch 2, Loss: 35307.5469\n",
            "Epoch 2, Loss: 34823.3711\n",
            "Epoch 2, Loss: 36325.9570\n",
            "Epoch 2, Loss: 35442.6914\n",
            "Epoch 2, Loss: 36226.2930\n",
            "Epoch 2, Loss: 38556.1562\n",
            "Epoch 2, Loss: 37736.6602\n",
            "Epoch 2, Loss: 35351.0859\n",
            "Epoch 2, Loss: 38729.7266\n",
            "Epoch 2, Loss: 36871.0273\n",
            "Epoch 2, Loss: 37136.0664\n",
            "Epoch 2, Loss: 35904.8633\n",
            "Epoch 2, Loss: 36549.1836\n",
            "Epoch 2, Loss: 36297.7852\n",
            "Epoch 2, Loss: 36028.5352\n",
            "Epoch 2, Loss: 36551.6758\n",
            "Epoch 2, Loss: 34595.4883\n",
            "Epoch 2, Loss: 39145.4180\n",
            "Epoch 2, Loss: 37997.8320\n",
            "Epoch 2, Loss: 38412.4883\n",
            "Epoch 2, Loss: 34955.2930\n",
            "Epoch 2, Loss: 15680.3965\n"
          ]
        }
      ]
    }
  ]
}